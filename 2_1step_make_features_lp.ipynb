{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c744b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36701f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "notebookstart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e3549",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749c5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple, Optional\n",
    "from ast import literal_eval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "register_heif_opener() # for using Image.open for .heic without changes\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77083f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28aa7cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b4e0e",
   "metadata": {},
   "source": [
    "# Блок для воспроизводимости результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1a88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed the RNG for all devices (both CPU and CUDA)\n",
    "#torch.manual_seed(1984)\n",
    "\n",
    "#Disabling the benchmarking feature causes cuDNN to deterministically select an algorithm, \n",
    "#possibly at the cost of reduced performance.\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# for custom operators,\n",
    "import random\n",
    "random.seed(5986721)\n",
    "\n",
    "# \n",
    "np.random.seed(62185)\n",
    "\n",
    "#sklearn take seed from a line abowe\n",
    "\n",
    "CB_RANDOMSEED  = 309487\n",
    "XGB_RANDOMSEED = 56\n",
    "LGB_RANDOMSEED = 874256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758092ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee1bba4a-6f41-42f2-8921-c1f753f19c47",
   "metadata": {},
   "source": [
    "# Выставление констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260b1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR_DATA = os.path.join(os.getcwd(), 'data')\n",
    "DIR_SUBM = os.path.join(os.getcwd(), 'subm')\n",
    "DIR_SUBM_TRAIN = os.path.join(os.getcwd(), 'subm', 'train')\n",
    "DIR_DATA_TRAIN = os.path.join(DIR_DATA, 'train')\n",
    "DIR_DATA_TEST  = os.path.join(DIR_DATA, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc6f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f772da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95972a7f",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1918c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DIR_DATA, 'train_upd.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DIR_DATA, 'test_upd.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16c4d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#115 img_1824.jpg - белая машина с белой рамкой"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3993bab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4204fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c3a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(outputchannels: Optional[int] = 1, aux_loss: Optional[bool] = False, freeze_backbone: Optional[bool] = False):\n",
    "    \"\"\"\n",
    "    Создание и настройка объекта модели для дальнейшей загрузки предобученных весов\n",
    "    args:\n",
    "        outputchannels - количество каналов для выхода модели (опционально, 1 - бинарный выход)\n",
    "        aux_loss - не используется в финальном решении\n",
    "        freeze_backbone - рассчитывать ли в дальнейшем обратный градиент\n",
    "    return:\n",
    "        настроенный объект модели\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(\n",
    "        pretrained = True, progress = True)#, aux_loss=aux_loss)\n",
    "\n",
    "    if freeze_backbone is True:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    #model.classifier = models.segmentation.segmentation.DeepLabHead(\n",
    "    model.classifier = models.segmentation.deeplabv3.DeepLabHead(\n",
    "        2048, outputchannels)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadaea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction pipeline\n",
    "def pred(inp_image: np.ndarray, inp_model):\n",
    "    \"\"\"\n",
    "    Предсказание модели. Предсказывает какие из пикселей изображения относятся к автомобильному номеру.\n",
    "    args:\n",
    "        inp_image - входное изображение\n",
    "        inp_model - используемая модель\n",
    "    return:\n",
    "        облако точек, относящихся к автомобильному номеру на данном изображении\n",
    "    \"\"\"\n",
    "    preprocess = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                    ])\n",
    "\n",
    "    input_tensor = preprocess(inp_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = inp_model(input_batch)['out'][0]\n",
    "    \n",
    "    return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c8cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_plate_features_tuple(inp_row: str, inp_folder: str, inp_model) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    \n",
    "    args:\n",
    "        inp_row - строка датафрейма. из нее берутся имя файла изображения и координаты рамки целевого автомобиля\n",
    "        inp_folder - папка изображений\n",
    "        inp_model - используемая модель\n",
    "    return:\n",
    "        мин и макс x и y координаты облака точек автомобильного номера на изображении\n",
    "    \"\"\"\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    \n",
    "    # найдена licence plate\n",
    "    if inp_row.car_y_min > 0:\n",
    "\n",
    "        img = Image.open(os.path.join(inp_folder, inp_row.image_name))\n",
    "        img = np.array(img)\n",
    "        sub_img = img[int(inp_row.car_y_min) : int(inp_row.car_y_max),\n",
    "                      int(inp_row.car_x_min) : int(inp_row.car_x_max)\n",
    "                     ]\n",
    "\n",
    "        # Defining a threshold for predictions\n",
    "        threshold = 0.1 # 0.1 seems appropriate for the pre-trained model\n",
    "\n",
    "        # Predict\n",
    "        output = pred(sub_img, inp_model)\n",
    "\n",
    "\n",
    "        output = (output > threshold).type(torch.IntTensor)\n",
    "        output_np = output.cpu().numpy()[0]\n",
    "\n",
    "        # Extracting coordinates\n",
    "        result = np.where(output_np > 0)\n",
    "        coords = list(zip(result[0], result[1]))\n",
    "\n",
    "        # интересуцют только мин и макс x и y\n",
    "        if len(coords) != 0:\n",
    "            x_min = sorted(coords, key = lambda x: x[0])[0][0]\n",
    "            y_min = sorted(coords, key = lambda x: x[1])[0][1]\n",
    "            x_max = sorted(coords, key = lambda x: x[0])[-1][0]\n",
    "            y_max = sorted(coords, key = lambda x: x[1])[-1][1]\n",
    "    \n",
    "    return (x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a6e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_plate_features(inp_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Извлекаем из Tuple мин и макс x и y координаты и делаем их отдельными признаками.\n",
    "    Расчет длинны и ширины по x и y.\n",
    "    args:\n",
    "        inp_df - входящий DataFrame для преобразования\n",
    "    return:\n",
    "        преобразованный DataFrame\n",
    "    \"\"\"\n",
    "    #inp_df.tmp = inp_df.tmp.apply(lambda x: (x))\n",
    "    \n",
    "    inp_df['plate_x_min'] = inp_df.tmp.apply(lambda x: float(x[0]))\n",
    "    inp_df['plate_y_min'] = inp_df.tmp.apply(lambda x: float(x[1]))\n",
    "    inp_df['plate_x_max'] = inp_df.tmp.apply(lambda x: float(x[2]))\n",
    "    inp_df['plate_y_max'] = inp_df.tmp.apply(lambda x: float(x[3]))\n",
    "    \n",
    "    inp_df['plate_w'] = inp_df.plate_x_max - inp_df.plate_x_min\n",
    "    inp_df['plate_h'] = inp_df.plate_y_max - inp_df.plate_y_min\n",
    "    \n",
    "    #inp_df.drop(['tmp'], axis = 0, inplace = True)\n",
    "    \n",
    "    return inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b1be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a92dd4a6-645f-4102-bbf9-9b2859d4d841",
   "metadata": {},
   "source": [
    "# Построение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fdb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model:\n",
    "model = create_model()\n",
    "checkpoint = torch.load('./models_weights/model_v2.pth', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.eval()\n",
    "_ = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0265caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('before ', train_df.shape, test_df.shape)\n",
    "train_df['tmp'] = train_df.progress_apply(lambda x: get_plate_features_tuple(x, DIR_DATA_TRAIN, model), axis = 1)\n",
    "test_df['tmp']  = test_df.progress_apply(lambda x: get_plate_features_tuple(x, DIR_DATA_TEST, model), axis = 1)\n",
    "print('after  ', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d667f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('before ', train_df.shape, test_df.shape)\n",
    "train_df = get_plate_features(train_df)\n",
    "test_df  = get_plate_features(test_df)\n",
    "print('after  ', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b01ce-f52e-4efc-85e7-750edf0b95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in ['plate_w', 'plate_h']:\n",
    "    train_df[f'log_{el}'] = train_df[el].apply(lambda x: np.log(x))\n",
    "    test_df[f'log_{el}']  = test_df[el].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69dea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(DIR_DATA, 'train_upd.csv'), index = False)\n",
    "test_df.to_csv(os.path.join(DIR_DATA,  'test_upd.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3d4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063dc202",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf383bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81ff83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9136f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
